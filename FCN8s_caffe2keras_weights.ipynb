{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download caffe model from YuvalNirkin's GitHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   608    0   608    0     0   2067      0 --:--:-- --:--:-- --:--:--  2068\n",
      "100  475M  100  475M    0     0  23.2M      0  0:00:20  0:00:20 --:--:-- 35.5M\n"
     ]
    }
   ],
   "source": [
    "!curl -L https://github.com/YuvalNirkin/face_segmentation/releases/download/1.0/face_seg_fcn8s.zip -o face_seg_fcn8s.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  face_seg_fcn8s.zip\n",
      "  inflating: face_seg_fcn8s_deploy.prototxt  \n",
      "  inflating: face_seg_fcn8s.caffemodel  \n"
     ]
    }
   ],
   "source": [
    "!unzip face_seg_fcn8s.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Import caffe & load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers_output = './layers'\n",
    "caffe_model = './face_seg_fcn8s.caffemodel'\n",
    "caffe_proto = './face_seg_fcn8s_deploy.prototxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_mode_cpu()\n",
    "net = caffe.Net(caffe_proto, caffe_model, caffe.TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('data', <caffe._caffe.Blob at 0x7fd53cfe4ed8>),\n",
       " ('data_input_0_split_0', <caffe._caffe.Blob at 0x7fd53cfe4e60>),\n",
       " ('data_input_0_split_1', <caffe._caffe.Blob at 0x7fd53d7c7050>),\n",
       " ('conv1_1', <caffe._caffe.Blob at 0x7fd53d7c70c8>),\n",
       " ('conv1_2', <caffe._caffe.Blob at 0x7fd53d7c7140>),\n",
       " ('pool1', <caffe._caffe.Blob at 0x7fd53d7c71b8>),\n",
       " ('conv2_1', <caffe._caffe.Blob at 0x7fd53d7c7230>),\n",
       " ('conv2_2', <caffe._caffe.Blob at 0x7fd53d7c72a8>),\n",
       " ('pool2', <caffe._caffe.Blob at 0x7fd53d7c7320>),\n",
       " ('conv3_1', <caffe._caffe.Blob at 0x7fd53d7c7398>),\n",
       " ('conv3_2', <caffe._caffe.Blob at 0x7fd53d7c7410>),\n",
       " ('conv3_3', <caffe._caffe.Blob at 0x7fd53d7c7488>),\n",
       " ('pool3', <caffe._caffe.Blob at 0x7fd53d7c7500>),\n",
       " ('pool3_pool3_0_split_0', <caffe._caffe.Blob at 0x7fd53d7c7578>),\n",
       " ('pool3_pool3_0_split_1', <caffe._caffe.Blob at 0x7fd53d7c75f0>),\n",
       " ('conv4_1', <caffe._caffe.Blob at 0x7fd53d7c7668>),\n",
       " ('conv4_2', <caffe._caffe.Blob at 0x7fd53d7c76e0>),\n",
       " ('conv4_3', <caffe._caffe.Blob at 0x7fd53d7c7758>),\n",
       " ('pool4', <caffe._caffe.Blob at 0x7fd53d7c77d0>),\n",
       " ('pool4_pool4_0_split_0', <caffe._caffe.Blob at 0x7fd53d7c7848>),\n",
       " ('pool4_pool4_0_split_1', <caffe._caffe.Blob at 0x7fd53d7c78c0>),\n",
       " ('conv5_1', <caffe._caffe.Blob at 0x7fd53d7c7938>),\n",
       " ('conv5_2', <caffe._caffe.Blob at 0x7fd53d7c79b0>),\n",
       " ('conv5_3', <caffe._caffe.Blob at 0x7fd53d7c7a28>),\n",
       " ('pool5', <caffe._caffe.Blob at 0x7fd53d7c7aa0>),\n",
       " ('fc6', <caffe._caffe.Blob at 0x7fd53d7c7b18>),\n",
       " ('fc7', <caffe._caffe.Blob at 0x7fd53d7c7b90>),\n",
       " ('score_fr', <caffe._caffe.Blob at 0x7fd53d7c7c08>),\n",
       " ('upscore2', <caffe._caffe.Blob at 0x7fd53d7c7c80>),\n",
       " ('upscore2_upscore2_0_split_0', <caffe._caffe.Blob at 0x7fd53d7c7cf8>),\n",
       " ('upscore2_upscore2_0_split_1', <caffe._caffe.Blob at 0x7fd53d7c7d70>),\n",
       " ('scale_pool4', <caffe._caffe.Blob at 0x7fd53d7c7de8>),\n",
       " ('score_pool4', <caffe._caffe.Blob at 0x7fd53d7c7e60>),\n",
       " ('score_pool4c', <caffe._caffe.Blob at 0x7fd53d7c7ed8>),\n",
       " ('fuse_pool4', <caffe._caffe.Blob at 0x7fd53d7c7f50>),\n",
       " ('upscore_pool4', <caffe._caffe.Blob at 0x7fd53d7c8050>),\n",
       " ('upscore_pool4_upscore_pool4_0_split_0',\n",
       "  <caffe._caffe.Blob at 0x7fd53d7c80c8>),\n",
       " ('upscore_pool4_upscore_pool4_0_split_1',\n",
       "  <caffe._caffe.Blob at 0x7fd53d7c8140>),\n",
       " ('scale_pool3', <caffe._caffe.Blob at 0x7fd53d7c81b8>),\n",
       " ('score_pool3', <caffe._caffe.Blob at 0x7fd53d7c8230>),\n",
       " ('score_pool3c', <caffe._caffe.Blob at 0x7fd53d7c82a8>),\n",
       " ('fuse_pool3', <caffe._caffe.Blob at 0x7fd53d7c8320>),\n",
       " ('upscore8', <caffe._caffe.Blob at 0x7fd53d7c8398>),\n",
       " ('score', <caffe._caffe.Blob at 0x7fd53d7c8410>)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.blobs.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv1_1', <caffe._caffe.BlobVec at 0x7fd53d79dbb0>),\n",
       " ('conv1_2', <caffe._caffe.BlobVec at 0x7fd53d79dad0>),\n",
       " ('conv2_1', <caffe._caffe.BlobVec at 0x7fd53d79d910>),\n",
       " ('conv2_2', <caffe._caffe.BlobVec at 0x7fd53d79d830>),\n",
       " ('conv3_1', <caffe._caffe.BlobVec at 0x7fd53d79d7c0>),\n",
       " ('conv3_2', <caffe._caffe.BlobVec at 0x7fd53d79da60>),\n",
       " ('conv3_3', <caffe._caffe.BlobVec at 0x7fd53d79d750>),\n",
       " ('conv4_1', <caffe._caffe.BlobVec at 0x7fd53d79d6e0>),\n",
       " ('conv4_2', <caffe._caffe.BlobVec at 0x7fd53d79d670>),\n",
       " ('conv4_3', <caffe._caffe.BlobVec at 0x7fd53d79d600>),\n",
       " ('conv5_1', <caffe._caffe.BlobVec at 0x7fd53d79d590>),\n",
       " ('conv5_2', <caffe._caffe.BlobVec at 0x7fd53d79d8a0>),\n",
       " ('conv5_3', <caffe._caffe.BlobVec at 0x7fd53d79d520>),\n",
       " ('fc6', <caffe._caffe.BlobVec at 0x7fd53d79d4b0>),\n",
       " ('fc7', <caffe._caffe.BlobVec at 0x7fd53d79d3d0>),\n",
       " ('score_fr', <caffe._caffe.BlobVec at 0x7fd53d79d2f0>),\n",
       " ('upscore2', <caffe._caffe.BlobVec at 0x7fd53d79d210>),\n",
       " ('scale_pool4', <caffe._caffe.BlobVec at 0x7fd53d79d1a0>),\n",
       " ('score_pool4', <caffe._caffe.BlobVec at 0x7fd53d79d130>),\n",
       " ('upscore_pool4', <caffe._caffe.BlobVec at 0x7fd53d79d0c0>),\n",
       " ('scale_pool3', <caffe._caffe.BlobVec at 0x7fd53d79d050>),\n",
       " ('score_pool3', <caffe._caffe.BlobVec at 0x7fd53d79d280>),\n",
       " ('upscore8', <caffe._caffe.BlobVec at 0x7fd53e2e5f30>)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.params.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save layers' weights to ./layers/*.npy\n",
    "\n",
    "Code borrows from https://github.com/michalfaber/keras_Realtime_Multi-Person_Pose_Estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_1\n",
      "(64, 3, 3, 3)\n",
      "(64,)\n",
      "conv1_2\n",
      "(64, 64, 3, 3)\n",
      "(64,)\n",
      "conv2_1\n",
      "(128, 64, 3, 3)\n",
      "(128,)\n",
      "conv2_2\n",
      "(128, 128, 3, 3)\n",
      "(128,)\n",
      "conv3_1\n",
      "(256, 128, 3, 3)\n",
      "(256,)\n",
      "conv3_2\n",
      "(256, 256, 3, 3)\n",
      "(256,)\n",
      "conv3_3\n",
      "(256, 256, 3, 3)\n",
      "(256,)\n",
      "conv4_1\n",
      "(512, 256, 3, 3)\n",
      "(512,)\n",
      "conv4_2\n",
      "(512, 512, 3, 3)\n",
      "(512,)\n",
      "conv4_3\n",
      "(512, 512, 3, 3)\n",
      "(512,)\n",
      "conv5_1\n",
      "(512, 512, 3, 3)\n",
      "(512,)\n",
      "conv5_2\n",
      "(512, 512, 3, 3)\n",
      "(512,)\n",
      "conv5_3\n",
      "(512, 512, 3, 3)\n",
      "(512,)\n",
      "fc6\n",
      "(4096, 512, 7, 7)\n",
      "(4096,)\n",
      "fc7\n",
      "(4096, 4096, 1, 1)\n",
      "(4096,)\n",
      "score_fr\n",
      "(21, 4096, 1, 1)\n",
      "(21,)\n",
      "upscore2\n",
      "(21, 21, 4, 4)\n",
      "scale_pool4\n",
      "(512,)\n",
      "score_pool4\n",
      "(21, 512, 1, 1)\n",
      "(21,)\n",
      "upscore_pool4\n",
      "(21, 21, 4, 4)\n",
      "scale_pool3\n",
      "(256,)\n",
      "score_pool3\n",
      "(21, 256, 1, 1)\n",
      "(21,)\n",
      "upscore8\n",
      "(21, 21, 16, 16)\n"
     ]
    }
   ],
   "source": [
    "#for layer_name, blob in net.blobs.items():\n",
    "#    print(layer_name, blob.data.shape)\n",
    "\n",
    "# write out weight matrices and bias vectors\n",
    "for k, v in net.params.items():\n",
    "    print(k)\n",
    "    print(v[0].data.shape)\n",
    "    try:\n",
    "        print(v[1].data.shape)\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        np.save(os.path.join(layers_output, \"W_{:s}.npy\".format(k)), v[0].data)\n",
    "    except:\n",
    "        None\n",
    "    try:\n",
    "        np.save(os.path.join(layers_output, \"b_{:s}.npy\".format(k)), v[1].data)\n",
    "    except:\n",
    "        None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## (Optional) Pack .npy files into a layers.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zipdir(path, ziph):\n",
    "    # ziph is zipfile handle\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            ziph.write(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zipf = zipfile.ZipFile('layers.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "zipdir('layers/', zipf)\n",
    "zipf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.activations import relu\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.applications import *\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create keras FCN8s model\n",
    "\n",
    "Code borrows from [jgraving/keras-fcn-1](https://github.com/jgraving/keras-fcn-1/blob/master/fcn/fcn.py), which is forked from [JihongJu/keras-fcn](https://github.com/JihongJu/keras-fcn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FCN8s_kers import FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights for all FCN8s layer\n",
    "\n",
    "Code borrows from https://github.com/michalfaber/keras_Realtime_Multi-Person_Pose_Estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_output = \"./layers\"\n",
    "start_style_time = time.time()\n",
    "\n",
    "for layer in model.layers:\n",
    "    layer_name = layer.name\n",
    "    if (os.path.exists(os.path.join(layers_output, \"W_%s.npy\" % layer_name))) and (layer_name[:10] != \"scale_pool\"):\n",
    "        print('Loading {}'.format(layer_name))\n",
    "        w = np.array(np.load(os.path.join(layers_output, \"W_%s.npy\" % layer_name)).tolist())\n",
    "        try:\n",
    "            b = np.array(np.load(os.path.join(layers_output, \"b_%s.npy\" % layer_name)).tolist())\n",
    "        except:\n",
    "          None\n",
    "\n",
    "        try:\n",
    "            w = np.transpose(w, (2, 3, 1, 0))\n",
    "        except:\n",
    "            None\n",
    "        \n",
    "        try:\n",
    "            layer_weights = [w, b]\n",
    "            layer.set_weights(layer_weights)\n",
    "        except:\n",
    "            layer_weights = [w]\n",
    "            layer.set_weights(layer_weights)\n",
    "\n",
    "end_style_time = time.time()\n",
    "print('Elapsed time in weights setting: %f' % (end_style_time - start_style_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save FCN8s model weights to a .h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"Keras_FCN8s_face_seg_YuvalNirkin.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
